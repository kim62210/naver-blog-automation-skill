"""
Gemini ì´ë¯¸ì§€ ìƒì„± API ì—°ë™ ëª¨ë“ˆ

Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ ì´ë¯¸ì§€ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
Gemini 2.5 Flashë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë©°, í•œë„ ì´ˆê³¼ ì‹œ Imagen 4ë¡œ í´ë°±í•©ë‹ˆë‹¤.
"""

import asyncio
import base64
import os
import re
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from .config import get_config, get_config_value


# API ì„¤ì • ìƒìˆ˜
DEFAULT_MODEL = "gemini-2.0-flash-exp"
FALLBACK_MODEL = "imagen-3.0-generate-002"
DEFAULT_SIZE = "1024x1024"
DEFAULT_TIMEOUT = 60
DEFAULT_RETRY_COUNT = 3
RATE_LIMIT_DELAY = 4.0  # ë¶„ë‹¹ 15íšŒ ì œí•œ ê³ ë ¤


@dataclass
class ImageResult:
    """ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""

    success: bool
    file_path: Optional[str] = None
    prompt: str = ""
    model_used: str = ""
    error_message: Optional[str] = None
    generation_time: float = 0.0

    def __str__(self) -> str:
        if self.success:
            return f"âœ… ìƒì„± ì™„ë£Œ: {self.file_path} ({self.model_used})"
        return f"âŒ ìƒì„± ì‹¤íŒ¨: {self.error_message}"


@dataclass
class BatchResult:
    """ë°°ì¹˜ ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼"""

    total: int = 0
    success_count: int = 0
    failed_count: int = 0
    results: List[ImageResult] = field(default_factory=list)
    total_time: float = 0.0

    @property
    def success_rate(self) -> float:
        if self.total == 0:
            return 0.0
        return (self.success_count / self.total) * 100

    def summary(self) -> str:
        return (
            f"ğŸ“Š ë°°ì¹˜ ìƒì„± ê²°ê³¼: {self.success_count}/{self.total} ì„±ê³µ "
            f"({self.success_rate:.1f}%), ì†Œìš”ì‹œê°„: {self.total_time:.1f}ì´ˆ"
        )


class GeminiImageGenerator:
    """
    Gemini APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„±ê¸°

    ì‚¬ìš© ì˜ˆì‹œ:
        generator = GeminiImageGenerator()
        result = await generator.generate_image(
            prompt="Blog thumbnail, modern design...",
            save_path="./images/01_thumbnail.png"
        )
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        primary_model: Optional[str] = None,
        fallback_model: Optional[str] = None,
    ):
        """
        GeminiImageGenerator ì´ˆê¸°í™”

        Args:
            api_key: Google API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
            primary_model: ê¸°ë³¸ ëª¨ë¸ (ê¸°ë³¸ê°’: gemini-2.0-flash-exp)
            fallback_model: í´ë°± ëª¨ë¸ (ê¸°ë³¸ê°’: imagen-3.0-generate-002)
        """
        self.api_key = api_key or self._load_api_key()
        self.primary_model = primary_model or self._get_config_model("primary") or DEFAULT_MODEL
        self.fallback_model = fallback_model or self._get_config_model("fallback") or FALLBACK_MODEL
        self.timeout = self._get_config_timeout() or DEFAULT_TIMEOUT
        self.retry_count = self._get_config_retry_count() or DEFAULT_RETRY_COUNT

        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (lazy loading)
        self._client = None

    def _load_api_key(self) -> str:
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤"""
        api_key = os.environ.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY")

        if not api_key:
            raise ValueError(
                "Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "í™˜ê²½ë³€ìˆ˜ GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."
            )

        return api_key

    def _get_config_model(self, model_type: str) -> Optional[str]:
        """config.yamlì—ì„œ ëª¨ë¸ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤"""
        config = get_config()
        return get_config_value(config, "gemini", "models", model_type)

    def _get_config_timeout(self) -> Optional[int]:
        """config.yamlì—ì„œ íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤"""
        config = get_config()
        return get_config_value(config, "gemini", "timeout")

    def _get_config_retry_count(self) -> Optional[int]:
        """config.yamlì—ì„œ ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤"""
        config = get_config()
        return get_config_value(config, "gemini", "retry_count")

    def _init_client(self):
        """Google Generative AI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"""
        if self._client is not None:
            return

        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self._client = genai
        except ImportError:
            raise ImportError(
                "google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "pip install google-generativeai ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”."
            )

    async def generate_image(
        self,
        prompt: str,
        save_path: Optional[str] = None,
        size: str = DEFAULT_SIZE,
        use_fallback: bool = True,
    ) -> ImageResult:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤

        Args:
            prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì˜ë¬¸ ê¶Œì¥)
            save_path: ì €ì¥ ê²½ë¡œ (ì—†ìœ¼ë©´ ì„ì‹œ íŒŒì¼ ìƒì„±)
            size: ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 1024x1024)
            use_fallback: ì‹¤íŒ¨ ì‹œ í´ë°± ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ImageResult: ìƒì„± ê²°ê³¼
        """
        start_time = datetime.now()

        # ê¸°ë³¸ ëª¨ë¸ë¡œ ì‹œë„
        result = await self._generate_with_model(
            prompt=prompt,
            save_path=save_path,
            size=size,
            model=self.primary_model,
        )

        # ì‹¤íŒ¨ ì‹œ í´ë°± ëª¨ë¸ ì‹œë„
        if not result.success and use_fallback and self._should_fallback(result.error_message):
            print(f"âš ï¸ {self.primary_model} ì‹¤íŒ¨, {self.fallback_model}ë¡œ ì¬ì‹œë„...")
            await asyncio.sleep(RATE_LIMIT_DELAY)

            result = await self._generate_with_model(
                prompt=prompt,
                save_path=save_path,
                size=size,
                model=self.fallback_model,
            )

        result.generation_time = (datetime.now() - start_time).total_seconds()
        return result

    def _should_fallback(self, error_message: Optional[str]) -> bool:
        """í´ë°± ì‹œë„ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤"""
        if not error_message:
            return True

        # í´ë°± íŠ¸ë¦¬ê±° ì¡°ê±´
        fallback_triggers = ["429", "QUOTA_EXCEEDED", "RATE_LIMIT", "ResourceExhausted"]
        return any(trigger in error_message for trigger in fallback_triggers)

    async def _generate_with_model(
        self,
        prompt: str,
        save_path: Optional[str],
        size: str,
        model: str,
    ) -> ImageResult:
        """íŠ¹ì • ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        self._init_client()

        for attempt in range(self.retry_count):
            try:
                # Gemini ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
                if model.startswith("gemini"):
                    return await self._generate_with_gemini(prompt, save_path, model)
                else:
                    return await self._generate_with_imagen(prompt, save_path, size, model)

            except Exception as e:
                error_msg = str(e)

                # Rate limit ì—ëŸ¬ ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                if "429" in error_msg or "ResourceExhausted" in error_msg:
                    if attempt < self.retry_count - 1:
                        wait_time = RATE_LIMIT_DELAY * (attempt + 1)
                        print(f"â³ Rate limit, {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                        await asyncio.sleep(wait_time)
                        continue

                # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                if attempt < self.retry_count - 1:
                    await asyncio.sleep(1)
                    continue

                return ImageResult(
                    success=False,
                    prompt=prompt,
                    model_used=model,
                    error_message=error_msg,
                )

        return ImageResult(
            success=False,
            prompt=prompt,
            model_used=model,
            error_message="ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼",
        )

    async def _generate_with_gemini(
        self,
        prompt: str,
        save_path: Optional[str],
        model: str,
    ) -> ImageResult:
        """Gemini ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        try:
            # Gemini 2.0 Flash ëª¨ë¸ ì„¤ì • (ì´ë¯¸ì§€ ìƒì„± ì§€ì›)
            generation_config = {
                "response_modalities": ["image", "text"],
            }

            gemini_model = self._client.GenerativeModel(
                model_name=model,
                generation_config=generation_config,
            )

            # ì´ë¯¸ì§€ ìƒì„± ìš”ì²­
            response = await asyncio.to_thread(
                gemini_model.generate_content,
                prompt,
            )

            # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
            image_data = None
            for part in response.candidates[0].content.parts:
                if hasattr(part, "inline_data") and part.inline_data.mime_type.startswith("image/"):
                    image_data = part.inline_data.data
                    break

            if not image_data:
                return ImageResult(
                    success=False,
                    prompt=prompt,
                    model_used=model,
                    error_message="ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                )

            # íŒŒì¼ ì €ì¥
            final_path = self._save_image(image_data, save_path, "png")

            return ImageResult(
                success=True,
                file_path=str(final_path),
                prompt=prompt,
                model_used=model,
            )

        except Exception as e:
            raise e

    async def _generate_with_imagen(
        self,
        prompt: str,
        save_path: Optional[str],
        size: str,
        model: str,
    ) -> ImageResult:
        """Imagen ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"""
        try:
            imagen_model = self._client.ImageGenerationModel(model_name=model)

            # í¬ê¸° íŒŒì‹±
            width, height = self._parse_size(size)

            # ì´ë¯¸ì§€ ìƒì„±
            response = await asyncio.to_thread(
                imagen_model.generate_images,
                prompt=prompt,
                number_of_images=1,
                aspect_ratio=self._get_aspect_ratio(width, height),
            )

            if not response.images:
                return ImageResult(
                    success=False,
                    prompt=prompt,
                    model_used=model,
                    error_message="ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤",
                )

            # ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥
            image_data = response.images[0]._image_bytes
            final_path = self._save_image(image_data, save_path, "png")

            return ImageResult(
                success=True,
                file_path=str(final_path),
                prompt=prompt,
                model_used=model,
            )

        except Exception as e:
            raise e

    def _parse_size(self, size: str) -> Tuple[int, int]:
        """í¬ê¸° ë¬¸ìì—´ì„ íŒŒì‹±í•©ë‹ˆë‹¤"""
        match = re.match(r"(\d+)x(\d+)", size)
        if match:
            return int(match.group(1)), int(match.group(2))
        return 1024, 1024

    def _get_aspect_ratio(self, width: int, height: int) -> str:
        """ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤"""
        ratio = width / height

        if abs(ratio - 1.0) < 0.1:
            return "1:1"
        elif abs(ratio - 16/9) < 0.1:
            return "16:9"
        elif abs(ratio - 9/16) < 0.1:
            return "9:16"
        elif abs(ratio - 4/3) < 0.1:
            return "4:3"
        elif abs(ratio - 3/4) < 0.1:
            return "3:4"
        else:
            return "1:1"

    def _save_image(
        self,
        image_data: bytes,
        save_path: Optional[str],
        ext: str = "png",
    ) -> Path:
        """ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤"""
        if save_path:
            path = Path(save_path)
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            path = Path(f"generated_image_{timestamp}.{ext}")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        path.parent.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ ì €ì¥
        with open(path, "wb") as f:
            if isinstance(image_data, str):
                f.write(base64.b64decode(image_data))
            else:
                f.write(image_data)

        return path

    async def generate_batch(
        self,
        prompts: List[Dict[str, str]],
        output_dir: str,
        concurrent_limit: int = 2,
    ) -> BatchResult:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì¼ê´„ ìƒì„±í•©ë‹ˆë‹¤

        Args:
            prompts: í”„ë¡¬í”„íŠ¸ ëª©ë¡ [{"prompt": "...", "filename": "..."}, ...]
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            concurrent_limit: ë™ì‹œ ì‹¤í–‰ ì œí•œ (ë¶„ë‹¹ 15íšŒ ì œí•œ ê³ ë ¤)

        Returns:
            BatchResult: ë°°ì¹˜ ìƒì„± ê²°ê³¼
        """
        start_time = datetime.now()
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        results: List[ImageResult] = []
        semaphore = asyncio.Semaphore(concurrent_limit)

        async def generate_with_limit(item: Dict[str, str]) -> ImageResult:
            async with semaphore:
                prompt = item.get("prompt", "")
                filename = item.get("filename", f"image_{len(results):02d}.png")
                save_path = str(output_path / filename)

                result = await self.generate_image(prompt=prompt, save_path=save_path)

                # Rate limit ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                await asyncio.sleep(RATE_LIMIT_DELAY)

                return result

        # ë³‘ë ¬ ì‹¤í–‰ (ì œí•œëœ ë™ì‹œì„±)
        tasks = [generate_with_limit(item) for item in prompts]
        results = await asyncio.gather(*tasks)

        # ê²°ê³¼ ì§‘ê³„
        success_count = sum(1 for r in results if r.success)
        total_time = (datetime.now() - start_time).total_seconds()

        return BatchResult(
            total=len(prompts),
            success_count=success_count,
            failed_count=len(prompts) - success_count,
            results=list(results),
            total_time=total_time,
        )


def create_generator(api_key: Optional[str] = None) -> GeminiImageGenerator:
    """
    GeminiImageGenerator ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜

    Args:
        api_key: Google API í‚¤ (ì„ íƒ)

    Returns:
        GeminiImageGenerator ì¸ìŠ¤í„´ìŠ¤
    """
    return GeminiImageGenerator(api_key=api_key)


# í¸ì˜ë¥¼ ìœ„í•œ ë™ê¸° ë˜í¼ í•¨ìˆ˜ë“¤
def generate_image_sync(
    prompt: str,
    save_path: Optional[str] = None,
    api_key: Optional[str] = None,
) -> ImageResult:
    """
    ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤

    Args:
        prompt: ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
        save_path: ì €ì¥ ê²½ë¡œ
        api_key: API í‚¤ (ì„ íƒ)

    Returns:
        ImageResult: ìƒì„± ê²°ê³¼
    """
    generator = create_generator(api_key)
    return asyncio.run(generator.generate_image(prompt=prompt, save_path=save_path))


def generate_batch_sync(
    prompts: List[Dict[str, str]],
    output_dir: str,
    api_key: Optional[str] = None,
) -> BatchResult:
    """
    ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤

    Args:
        prompts: í”„ë¡¬í”„íŠ¸ ëª©ë¡
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        api_key: API í‚¤ (ì„ íƒ)

    Returns:
        BatchResult: ë°°ì¹˜ ìƒì„± ê²°ê³¼
    """
    generator = create_generator(api_key)
    return asyncio.run(generator.generate_batch(prompts=prompts, output_dir=output_dir))
