"""
ì´ë¯¸ì§€ ìˆ˜ì§‘ ëª¨ë“ˆ

URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , íŒŒì¼ëª…ì„ ìƒì„±í•˜ë©°, ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import hashlib
import mimetypes
import re
import urllib.request
import urllib.error
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Dict, Any
from urllib.parse import urlparse

from .config import get_config, get_config_value
from .utils import format_image_filename, extract_extension_from_url
from .setup import update_metadata


@dataclass
class ImageInfo:
    """ì´ë¯¸ì§€ ì •ë³´"""
    url: str                         # ì›ë³¸ URL
    source_url: str                  # ì¶œì²˜ í˜ì´ì§€ URL
    source_name: str                 # ì¶œì²˜ëª… (ë‰´ìŠ¤/ë¸”ë¡œê·¸/ê²€ìƒ‰)
    description: str                 # ì„¤ëª…
    image_type: str                  # ìœ í˜• (ì¸í¬ê·¸ë˜í”½/í‘œ/ì¼ëŸ¬ìŠ¤íŠ¸/ì‚¬ì§„)
    filename: Optional[str] = None   # ì €ì¥ëœ íŒŒì¼ëª…
    local_path: Optional[Path] = None  # ë¡œì»¬ ì €ì¥ ê²½ë¡œ
    downloaded: bool = False         # ë‹¤ìš´ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    error: Optional[str] = None      # ì˜¤ë¥˜ ë©”ì‹œì§€


@dataclass
class CollectionResult:
    """ìˆ˜ì§‘ ê²°ê³¼"""
    total: int                       # ì´ ìˆ˜ì§‘ ì‹œë„ ìˆ˜
    success: int                     # ì„±ê³µ ìˆ˜
    failed: int                      # ì‹¤íŒ¨ ìˆ˜
    images: List[ImageInfo] = field(default_factory=list)  # ì´ë¯¸ì§€ ëª©ë¡


def download_image(
    url: str,
    save_path: Path,
    timeout: int = 30,
    user_agent: Optional[str] = None
) -> bool:
    """
    ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        url: ì´ë¯¸ì§€ URL
        save_path: ì €ì¥ ê²½ë¡œ
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        user_agent: User-Agent í—¤ë”

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    config = get_config()

    if user_agent is None:
        user_agent = get_config_value(
            config, "images", "user_agent",
            default="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        )

    try:
        request = urllib.request.Request(url)
        request.add_header("User-Agent", user_agent)
        request.add_header("Accept", "image/*")

        with urllib.request.urlopen(request, timeout=timeout) as response:
            content = response.read()

            # ìµœì†Œ í¬ê¸° í™•ì¸ (100 bytes ì´ìƒ)
            if len(content) < 100:
                return False

            save_path.parent.mkdir(parents=True, exist_ok=True)

            with open(save_path, "wb") as f:
                f.write(content)

            return True

    except (urllib.error.URLError, urllib.error.HTTPError, TimeoutError) as e:
        return False
    except Exception as e:
        return False


def collect_images(
    images: List[Dict[str, str]],
    output_dir: Path,
    config: Optional[Dict] = None
) -> CollectionResult:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

    Args:
        images: ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{"url", "source_url", "source_name", "description", "type"}]
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬

    Returns:
        CollectionResult ê°ì²´
    """
    if config is None:
        config = get_config()

    timeout = get_config_value(config, "images", "download_timeout", default=30)
    images_dir = output_dir / "images"
    images_dir.mkdir(exist_ok=True)

    result = CollectionResult(total=len(images), success=0, failed=0)

    for idx, img_data in enumerate(images, 1):
        url = img_data.get("url", "")
        source_url = img_data.get("source_url", "")
        source_name = img_data.get("source_name", "ê²€ìƒ‰")
        description = img_data.get("description", f"ì´ë¯¸ì§€{idx}")
        image_type = img_data.get("type", "ê¸°íƒ€")

        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
        extension = extract_extension_from_url(url)

        # íŒŒì¼ëª… ìƒì„±
        filename = format_image_filename(idx, source_name, description, extension)
        save_path = images_dir / filename

        image_info = ImageInfo(
            url=url,
            source_url=source_url,
            source_name=source_name,
            description=description,
            image_type=image_type,
            filename=filename,
        )

        # ë‹¤ìš´ë¡œë“œ ì‹œë„
        success = download_image(url, save_path, timeout=timeout)

        if success:
            image_info.downloaded = True
            image_info.local_path = save_path
            result.success += 1
        else:
            image_info.downloaded = False
            image_info.error = "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"
            result.failed += 1

        result.images.append(image_info)

    return result


def validate_image_url(url: str) -> bool:
    """
    ì´ë¯¸ì§€ URLì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.

    Args:
        url: ì´ë¯¸ì§€ URL

    Returns:
        ìœ íš¨ ì—¬ë¶€
    """
    if not url:
        return False

    try:
        parsed = urlparse(url)

        # ìŠ¤í‚´ í™•ì¸
        if parsed.scheme not in ("http", "https"):
            return False

        # í˜¸ìŠ¤íŠ¸ í™•ì¸
        if not parsed.netloc:
            return False

        # ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸ (ì„ íƒì )
        image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.bmp')
        path_lower = parsed.path.lower()

        # í™•ì¥ìê°€ ìˆìœ¼ë©´ ì´ë¯¸ì§€ í™•ì¥ìì¸ì§€ í™•ì¸
        if '.' in parsed.path:
            return any(path_lower.endswith(ext) for ext in image_extensions)

        # í™•ì¥ìê°€ ì—†ìœ¼ë©´ ì¼ë‹¨ í—ˆìš© (CDN ë“±)
        return True

    except Exception:
        return False


def generate_image_metadata(images: List[ImageInfo]) -> List[Dict[str, Any]]:
    """
    ì´ë¯¸ì§€ ëª©ë¡ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        images: ImageInfo ë¦¬ìŠ¤íŠ¸

    Returns:
        ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    metadata = []

    for img in images:
        entry = {
            "filename": img.filename,
            "url": img.url,
            "source_url": img.source_url,
            "source_name": img.source_name,
            "description": img.description,
            "type": img.image_type,
            "downloaded": img.downloaded,
        }

        if img.local_path and img.downloaded:
            entry["local_path"] = str(img.local_path)
            entry["size"] = img.local_path.stat().st_size if img.local_path.exists() else 0

        if img.error:
            entry["error"] = img.error

        metadata.append(entry)

    return metadata


def save_collection_result(
    result: CollectionResult,
    project_path: Path
) -> None:
    """
    ìˆ˜ì§‘ ê²°ê³¼ë¥¼ ë©”íƒ€ë°ì´í„° íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        result: CollectionResult ê°ì²´
        project_path: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    metadata = generate_image_metadata(result.images)

    update_metadata(project_path, {
        "images": metadata,
        "collection_stats": {
            "total": result.total,
            "success": result.success,
            "failed": result.failed,
        }
    })


def print_collection_report(result: CollectionResult) -> None:
    """
    ìˆ˜ì§‘ ê²°ê³¼ ë³´ê³ ì„œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        result: CollectionResult ê°ì²´
    """
    print("=" * 50)
    print("ğŸ“· ì´ë¯¸ì§€ ìˆ˜ì§‘ ê²°ê³¼")
    print("=" * 50)
    print(f"ì´ ì‹œë„: {result.total}ê±´")
    print(f"ì„±ê³µ: {result.success}ê±´")
    print(f"ì‹¤íŒ¨: {result.failed}ê±´")
    print("-" * 50)

    if result.success > 0:
        print("\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ:")
        for img in result.images:
            if img.downloaded:
                print(f"  - {img.filename}")
                print(f"    â”” {img.description} ({img.image_type})")

    if result.failed > 0:
        print("\nâŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (URLë§Œ ê¸°ë¡):")
        for img in result.images:
            if not img.downloaded:
                print(f"  - {img.description}: {img.error}")
                print(f"    â”” URL: {img.url[:50]}...")

    print("=" * 50)


def create_image_list_from_search_results(
    search_results: List[Dict[str, Any]],
    source_name: str
) -> List[Dict[str, str]]:
    """
    ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        search_results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        source_name: ì¶œì²˜ëª…

    Returns:
        ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    images = []

    for result in search_results:
        # ì´ë¯¸ì§€ URL ì¶”ì¶œ (ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›)
        image_url = (
            result.get("image_url") or
            result.get("thumbnail") or
            result.get("og_image") or
            result.get("image")
        )

        if not image_url or not validate_image_url(image_url):
            continue

        images.append({
            "url": image_url,
            "source_url": result.get("url", ""),
            "source_name": source_name,
            "description": result.get("title", "")[:30],
            "type": result.get("image_type", "ê¸°íƒ€"),
        })

    return images


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    test_images = [
        {
            "url": "https://example.com/test.jpg",
            "source_url": "https://example.com",
            "source_name": "í…ŒìŠ¤íŠ¸",
            "description": "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€",
            "type": "ê¸°íƒ€",
        }
    ]

    from pathlib import Path
    test_dir = Path("./test_output")

    result = collect_images(test_images, test_dir)
    print_collection_report(result)
