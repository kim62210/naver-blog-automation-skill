"""
Image collection module

Downloads images from URLs, generates filenames, and extracts metadata.
"""

import hashlib
import mimetypes
import re
import urllib.request
import urllib.error
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Dict, Any
from urllib.parse import urlparse

from .config import get_config, get_config_value
from .utils import format_image_filename, extract_extension_from_url
from .setup import update_metadata


@dataclass
class ImageInfo:
    """Image information"""
    url: str                         # Original URL
    source_url: str                  # Source page URL
    source_name: str                 # Source name (ë‰´ìŠ¤/ë¸”ë¡œê·¸/ê²€ìƒ‰)
    description: str                 # Description
    image_type: str                  # Type (ì¸í¬ê·¸ë˜í”½/í‘œ/ì¼ëŸ¬ìŠ¤íŠ¸/ì‚¬ì§„)
    filename: Optional[str] = None   # Saved filename
    local_path: Optional[Path] = None  # Local storage path
    downloaded: bool = False         # Download success status
    error: Optional[str] = None      # Error message


@dataclass
class CollectionResult:
    """Collection result"""
    total: int                       # Total collection attempts
    success: int                     # Success count
    failed: int                      # Failure count
    images: List[ImageInfo] = field(default_factory=list)  # Image list


def download_image(
    url: str,
    save_path: Path,
    timeout: int = 30,
    user_agent: Optional[str] = None
) -> bool:
    """
    Download an image.

    Args:
        url: Image URL
        save_path: Save path
        timeout: Timeout (seconds)
        user_agent: User-Agent header

    Returns:
        Success status
    """
    config = get_config()

    if user_agent is None:
        user_agent = get_config_value(
            config, "images", "user_agent",
            default="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        )

    try:
        request = urllib.request.Request(url)
        request.add_header("User-Agent", user_agent)
        request.add_header("Accept", "image/*")

        with urllib.request.urlopen(request, timeout=timeout) as response:
            content = response.read()

            # Check minimum size (100 bytes or more)
            if len(content) < 100:
                return False

            save_path.parent.mkdir(parents=True, exist_ok=True)

            with open(save_path, "wb") as f:
                f.write(content)

            return True

    except (urllib.error.URLError, urllib.error.HTTPError, TimeoutError) as e:
        return False
    except Exception as e:
        return False


def collect_images(
    images: List[Dict[str, str]],
    output_dir: Path,
    config: Optional[Dict] = None
) -> CollectionResult:
    """
    Collect multiple images.

    Args:
        images: Image info list [{"url", "source_url", "source_name", "description", "type"}]
        output_dir: Output directory
        config: Configuration dictionary

    Returns:
        CollectionResult object
    """
    if config is None:
        config = get_config()

    timeout = get_config_value(config, "images", "download_timeout", default=30)
    images_dir = output_dir / "images"
    images_dir.mkdir(exist_ok=True)

    result = CollectionResult(total=len(images), success=0, failed=0)

    for idx, img_data in enumerate(images, 1):
        url = img_data.get("url", "")
        source_url = img_data.get("source_url", "")
        source_name = img_data.get("source_name", "ê²€ìƒ‰")
        description = img_data.get("description", f"ì´ë¯¸ì§€{idx}")
        image_type = img_data.get("type", "ê¸°íƒ€")

        # Extract file extension
        extension = extract_extension_from_url(url)

        # Generate filename
        filename = format_image_filename(idx, source_name, description, extension)
        save_path = images_dir / filename

        image_info = ImageInfo(
            url=url,
            source_url=source_url,
            source_name=source_name,
            description=description,
            image_type=image_type,
            filename=filename,
        )

        # Attempt download
        success = download_image(url, save_path, timeout=timeout)

        if success:
            image_info.downloaded = True
            image_info.local_path = save_path
            result.success += 1
        else:
            image_info.downloaded = False
            image_info.error = "Download failed"
            result.failed += 1

        result.images.append(image_info)

    return result


def validate_image_url(url: str) -> bool:
    """
    Validate image URL.

    Args:
        url: Image URL

    Returns:
        Validity status
    """
    if not url:
        return False

    try:
        parsed = urlparse(url)

        # Check scheme
        if parsed.scheme not in ("http", "https"):
            return False

        # Check host
        if not parsed.netloc:
            return False

        # Check image extension (optional)
        image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.bmp')
        path_lower = parsed.path.lower()

        # If extension exists, verify it's an image extension
        if '.' in parsed.path:
            return any(path_lower.endswith(ext) for ext in image_extensions)

        # Allow if no extension (CDN, etc.)
        return True

    except Exception:
        return False


def generate_image_metadata(images: List[ImageInfo]) -> List[Dict[str, Any]]:
    """
    Generate metadata from image list.

    Args:
        images: ImageInfo list

    Returns:
        Metadata dictionary list
    """
    metadata = []

    for img in images:
        entry = {
            "filename": img.filename,
            "url": img.url,
            "source_url": img.source_url,
            "source_name": img.source_name,
            "description": img.description,
            "type": img.image_type,
            "downloaded": img.downloaded,
        }

        if img.local_path and img.downloaded:
            entry["local_path"] = str(img.local_path)
            entry["size"] = img.local_path.stat().st_size if img.local_path.exists() else 0

        if img.error:
            entry["error"] = img.error

        metadata.append(entry)

    return metadata


def save_collection_result(
    result: CollectionResult,
    project_path: Path
) -> None:
    """
    Save collection result to metadata file.

    Args:
        result: CollectionResult object
        project_path: Project directory path
    """
    metadata = generate_image_metadata(result.images)

    update_metadata(project_path, {
        "images": metadata,
        "collection_stats": {
            "total": result.total,
            "success": result.success,
            "failed": result.failed,
        }
    })


def print_collection_report(result: CollectionResult) -> None:
    """
    Print collection result report.

    Args:
        result: CollectionResult object
    """
    print("=" * 50)
    print("ğŸ“· Image Collection Result")
    print("=" * 50)
    print(f"Total attempts: {result.total}")
    print(f"Success: {result.success}")
    print(f"Failed: {result.failed}")
    print("-" * 50)

    if result.success > 0:
        print("\nâœ… Downloads completed:")
        for img in result.images:
            if img.downloaded:
                print(f"  - {img.filename}")
                print(f"    â”” {img.description} ({img.image_type})")

    if result.failed > 0:
        print("\nâŒ Downloads failed (URL recorded):")
        for img in result.images:
            if not img.downloaded:
                print(f"  - {img.description}: {img.error}")
                print(f"    â”” URL: {img.url[:50]}...")

    print("=" * 50)


def create_image_list_from_search_results(
    search_results: List[Dict[str, Any]],
    source_name: str
) -> List[Dict[str, str]]:
    """
    Create image list from search results.

    Args:
        search_results: Search result list
        source_name: Source name

    Returns:
        Image info list
    """
    images = []

    for result in search_results:
        # Extract image URL (support various field names)
        image_url = (
            result.get("image_url") or
            result.get("thumbnail") or
            result.get("og_image") or
            result.get("image")
        )

        if not image_url or not validate_image_url(image_url):
            continue

        images.append({
            "url": image_url,
            "source_url": result.get("url", ""),
            "source_name": source_name,
            "description": result.get("title", "")[:30],
            "type": result.get("image_type", "ê¸°íƒ€"),
        })

    return images


if __name__ == "__main__":
    # Test
    test_images = [
        {
            "url": "https://example.com/test.jpg",
            "source_url": "https://example.com",
            "source_name": "í…ŒìŠ¤íŠ¸",
            "description": "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€",
            "type": "ê¸°íƒ€",
        }
    ]

    from pathlib import Path
    test_dir = Path("./test_output")

    result = collect_images(test_images, test_dir)
    print_collection_report(result)
